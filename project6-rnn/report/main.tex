\documentclass[11pt]{article}
\usepackage[margin=0.9in]{geometry}
\usepackage{amsmath, graphicx}
%\usepackage{setspace}
%\doublespacing

\title{ECE 692 Project 6: Recurrent neural networks}
\author{Devanshu Agrawal}
\date{November 30, 2018}

\begin{document}
\maketitle

\section{Word2Vec and Character-level RNN}

I ran Shang's code without modification. I first used word2vec to generate word embeddings of the 20-Newsgroup data set and used t-SNE to visualize the embeddings in 2D (Figure \ref{fig-tsne1}).

\begin{figure}
\centering
\includegraphics[width=4in]{../task1/plot.png}
\caption{\label{fig-tsne1} T-SNE visualization of 50D word embeddings of the 20-Newsgroup Data set.}
\end{figure}

I also implemented a character-level RNN language model on \textit{Hitchhiker's Guide to the Galaxy} and generated sample text at regular intervals of training (Table \ref{table-sample1}).

\begin{table}
\centering
\caption{\label{table-sample1} Sample text generated by a character-level RNN trained on \textit{Hitchhiker's Guide to the Galaxy} after various number of training iterations.}
\begin{tabular}{|c|c|} \hline
Iterations & Sample text \\ \hline
500 & e  ee  ae  ae  ae  ae  ae  ae  ae  ae  ae  \\
\quad & ae  ae  ae  ae  ae  ae  ae  ae  ae  ae  ae  ae  ae  ae  a \\ \hline
5000 & n the said the said the said the said the said \\
\quad & the said the said the said the said the said the said \\ \hline
5000 & ith the start of the stare of the stare of the stare \\
\quad & of the stare of the stare of the stare of the s \\ \hline
100000 & les of the sun was the sun which was the computer \\
\quad & beard to the entire of the ship and the ship and t \\
\hline
\end{tabular}
\end{table}


\section{Word2Vec on an example corpus}

I chose \textit{The Hobbit} by JRR Tolkien as my example corpus. I implemented word2vec to generate word embeddings of the text. I chose an embedding dimension of 200 and trained word2vec for 20 iterations. I used t-SNE to visualize the embeddings in 2D (Figure \ref{fig-tsne2}).

\begin{figure}
\centering
\includegraphics[width=4in]{../task2-3/plot.png}
\caption{\label{fig-tsne2} T-SNE visualization of 200D word embeddings of \textit{The Hobbit}}.
\end{figure}

\section{Word-level RNN on an example corpus}

I then implemented a word-level RNN language model on \textit{The Hobbit}. I added an embedding layer at the beginning of the RNN that performs a look-up in the word embeddings obtained above in order to embed the input words. For the output, I first calculated a ``dual embedding matrix'' (dual in the sense of frame theory); I project the 200D output of the RNN onto the dual embedding layer and then pass the projections through a softmax to get a predictive distribution over the vocabulary (about 1800 unique words). I allowed both the embedding and dual embedding layers to be trainable. I generated 25-word sample texts after every 100 iterations of training (Table \ref{table-sample2}). The samples clearly improve with training.

\begin{table}
\centering
\caption{\label{table-sample2} Sample text generated by a word-level RNN trained on \textit{The Hobbit} after various number of training iterations.}
\begin{tabular}{|c|c|} \hline
Iterations & Sample text \\ \hline
500 & and and the of the of the of the of the of the the \\
\quad & of the of the the of the of the the of  \\ \hline
5000 & not to be to the of the mountain and the mountain and \\
\quad & the mountain and the mountain and the mountain and the mountain and the \\ \hline
50000 & of a and a little of a and a little of a \\
\quad & and a little of a and a little of a and a little \\ \hline
58500 & for a long while the dwarves were all round again and they \\
\quad & were all in the dark bilbo was in the middle of the great \\
\hline
\end{tabular}
\end{table}


\section{Paper discussion}

In (Conneau 2016), the authors introduce the ``very deep convolutional neural network'' (VDCNN) for text classification. The authors note that CNNs have been very successful in computer vision and that a theme in the application of CNNs to computer vision is going deeper. The authors argue that text is not too different from images in the sense that text is hierarchical just like images-- characters form words, which form $n$-grams, which form phrases, which form sentences , etc. The authors therefore develop a deep CNN architecture adapted for text classification. Their architecture has 29 convolutional layers-- much deeper than previous CNN models for text. The first layer acts on the character level. The idea is that the deep architecture will organize the characters into a hierarchical structure that will be useful for the classification task at hand. The VDCNN model achieves better performance than previous CNN models for text.

In (Yang 2016), the authors introduce the "hierarchical attention network'' (HAN) for text classification. Like (Conneau 2016), the authors note how text follows a hierarchical organization-- e.g., words to sentences to documents. But the authors do not make comparisons to computer vision. The idea is first to apply an RNN as is usual. The output of the RNN at each time step is understood as a ``word annotation''. Each word annotation is passed through an MLP and is then compared to a word-level ``context vector''. Finally, all word-context similarities are passed through a softmax and are interpreted as word importances. This is the attention mechanism. This procedure is similarly applied at the sentence level-- hence the hierarchical architecture. So the idea of HAN is not to use convolution to group words but instead to use attention to organize; i.e., we need to impose some topology on words. CNNs do this through a convolution window, while HANs do this through a similarity with context vectors. The HAN achieves state-of-the-art performance.

\end{document}